{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "target_size = (image_size, image_size)\n",
    "input_shape = (image_size, image_size, 3)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"./dataset\"\n",
    "train_dir = os.path.join(base_dir,\"train\")\n",
    "test_dir = os.path.join(base_dir,\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.0,\n",
    "                                                             shear_range = 0.2,\n",
    "                                                             zoom_range = 0.2,\n",
    "                                                             width_shift_range = 0.2,\n",
    "                                                             height_shift_range = 0.2,\n",
    "                                                             fill_mode=\"nearest\")\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4322 images belonging to 10 classes.\n",
      "Found 1772 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               target_size = (image_size, image_size),\n",
    "                                               batch_size = batch_size,\n",
    "                                               class_mode = \"categorical\")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(test_dir,\n",
    "                                             target_size = (image_size, image_size),\n",
    "                                             batch_size = batch_size,\n",
    "                                             class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phosphorus': 0, 'Potassium': 1, 'boron': 2, 'calcium': 3, 'iron': 4, 'magnesium': 5, 'manganese': 6, 'molybdenum': 7, 'nitrogen': 8, 'zinc': 9}\n"
     ]
    }
   ],
   "source": [
    "categories = list(train_data.class_indices.keys())\n",
    "print(train_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 24s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_model = tf.keras.applications.DenseNet201(weights = \"imagenet\",\n",
    "                                             include_top = False,\n",
    "                                             input_shape = input_shape)\n",
    "\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = keras.Input(shape = input_shape)\n",
    "\n",
    "x = base_model(inputs, training = False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(10, \n",
    "                          activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs = inputs, \n",
    "                    outputs = x, \n",
    "                    name=\"LeafDisease_MobileNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam() #lr=0.05 --- Mention LR here, default - 0.01\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "              loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy(), \n",
    "                       'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 205s 18s/step - loss: 2.4807 - categorical_accuracy: 0.1141 - accuracy: 0.1141 - val_loss: 2.4694 - val_categorical_accuracy: 0.1156 - val_accuracy: 0.1156\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 161s 16s/step - loss: 2.3864 - categorical_accuracy: 0.1295 - accuracy: 0.1295 - val_loss: 2.4658 - val_categorical_accuracy: 0.1344 - val_accuracy: 0.1344\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 163s 17s/step - loss: 2.2997 - categorical_accuracy: 0.1516 - accuracy: 0.1516 - val_loss: 2.2754 - val_categorical_accuracy: 0.2062 - val_accuracy: 0.2062\n",
      "Epoch 4/10\n",
      " 9/10 [==========================>...] - ETA: 10s - loss: 2.2722 - categorical_accuracy: 0.1545 - accuracy: 0.1545"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonny\\anaconda3\\lib\\site-packages\\PIL\\Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 162s 16s/step - loss: 2.2554 - categorical_accuracy: 0.1625 - accuracy: 0.1625 - val_loss: 2.3510 - val_categorical_accuracy: 0.1750 - val_accuracy: 0.1750\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 163s 17s/step - loss: 2.2558 - categorical_accuracy: 0.1969 - accuracy: 0.1969 - val_loss: 2.2353 - val_categorical_accuracy: 0.1656 - val_accuracy: 0.1656\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 163s 17s/step - loss: 2.2459 - categorical_accuracy: 0.1859 - accuracy: 0.1859 - val_loss: 2.3012 - val_categorical_accuracy: 0.1750 - val_accuracy: 0.1750\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 141s 14s/step - loss: 2.2310 - categorical_accuracy: 0.2047 - accuracy: 0.2047 - val_loss: 2.2348 - val_categorical_accuracy: 0.2031 - val_accuracy: 0.2031\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 136s 14s/step - loss: 2.1976 - categorical_accuracy: 0.2213 - accuracy: 0.2213 - val_loss: 2.2493 - val_categorical_accuracy: 0.2125 - val_accuracy: 0.2125\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 141s 14s/step - loss: 2.1295 - categorical_accuracy: 0.2266 - accuracy: 0.2266 - val_loss: 2.2388 - val_categorical_accuracy: 0.1937 - val_accuracy: 0.1937\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 135s 14s/step - loss: 2.1830 - categorical_accuracy: 0.2234 - accuracy: 0.2234 - val_loss: 2.2407 - val_categorical_accuracy: 0.1875 - val_accuracy: 0.1875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(train_data,\n",
    "                    validation_data=test_data,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=10,\n",
    "                    validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 27s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model2 = tf.keras.applications.ResNet50(weights = \"imagenet\",\n",
    "                                             include_top = False,\n",
    "                                             input_shape = input_shape)\n",
    "\n",
    "base_model2.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape = input_shape)\n",
    "\n",
    "x = base_model2(inputs, training = False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(10, \n",
    "                          activation=\"softmax\")(x)\n",
    "\n",
    "model2 = keras.Model(inputs = inputs, \n",
    "                    outputs = x, \n",
    "                    name=\"LeafDisease_MobileNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam() #lr=0.05 --- Mention LR here, default - 0.01\n",
    "\n",
    "model2.compile(optimizer = optimizer,\n",
    "              loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy(), \n",
    "                       'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonny\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4869: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 108s 10s/step - loss: 2.5728 - categorical_accuracy: 0.0639 - accuracy: 0.0639 - val_loss: 2.3234 - val_categorical_accuracy: 0.0938 - val_accuracy: 0.0938\n",
      "Epoch 2/10\n",
      " 1/10 [==>...........................] - ETA: 1:25 - loss: 2.2937 - categorical_accuracy: 0.1406 - accuracy: 0.1406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonny\\anaconda3\\lib\\site-packages\\PIL\\Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 95s 9s/step - loss: 2.3127 - categorical_accuracy: 0.1000 - accuracy: 0.1000 - val_loss: 2.3156 - val_categorical_accuracy: 0.0906 - val_accuracy: 0.0906\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 91s 9s/step - loss: 2.2932 - categorical_accuracy: 0.1344 - accuracy: 0.1344 - val_loss: 2.3176 - val_categorical_accuracy: 0.1250 - val_accuracy: 0.1250\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 93s 9s/step - loss: 2.2839 - categorical_accuracy: 0.1219 - accuracy: 0.1219 - val_loss: 2.3209 - val_categorical_accuracy: 0.0938 - val_accuracy: 0.0938\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 93s 9s/step - loss: 2.3018 - categorical_accuracy: 0.1141 - accuracy: 0.1141 - val_loss: 2.2920 - val_categorical_accuracy: 0.1156 - val_accuracy: 0.1156\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 87s 9s/step - loss: 2.2932 - categorical_accuracy: 0.1187 - accuracy: 0.1187 - val_loss: 2.2971 - val_categorical_accuracy: 0.0969 - val_accuracy: 0.0969\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 98s 10s/step - loss: 2.2976 - categorical_accuracy: 0.0875 - accuracy: 0.0875 - val_loss: 2.2783 - val_categorical_accuracy: 0.1063 - val_accuracy: 0.1063\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 88s 9s/step - loss: 2.2764 - categorical_accuracy: 0.1078 - accuracy: 0.1078 - val_loss: 2.2756 - val_categorical_accuracy: 0.1594 - val_accuracy: 0.1594\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 93s 9s/step - loss: 2.2850 - categorical_accuracy: 0.1109 - accuracy: 0.1109 - val_loss: 2.3462 - val_categorical_accuracy: 0.0906 - val_accuracy: 0.0906\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 88s 9s/step - loss: 2.2802 - categorical_accuracy: 0.1172 - accuracy: 0.1172 - val_loss: 2.3102 - val_categorical_accuracy: 0.1187 - val_accuracy: 0.1187\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history2 = model2.fit(train_data,\n",
    "                    validation_data=test_data,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=10,\n",
    "                    validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 86s 9s/step - loss: 2.2833 - categorical_accuracy: 0.1375 - accuracy: 0.1375 - val_loss: 2.2646 - val_categorical_accuracy: 0.1406 - val_accuracy: 0.1406\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 84s 9s/step - loss: 2.2885 - categorical_accuracy: 0.1094 - accuracy: 0.1094 - val_loss: 2.3173 - val_categorical_accuracy: 0.1125 - val_accuracy: 0.1125\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 85s 9s/step - loss: 2.2821 - categorical_accuracy: 0.1141 - accuracy: 0.1141 - val_loss: 2.2844 - val_categorical_accuracy: 0.1469 - val_accuracy: 0.1469\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 84s 9s/step - loss: 2.2850 - categorical_accuracy: 0.1250 - accuracy: 0.1250 - val_loss: 2.2912 - val_categorical_accuracy: 0.1250 - val_accuracy: 0.1250\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 83s 8s/step - loss: 2.2879 - categorical_accuracy: 0.1063 - accuracy: 0.1063 - val_loss: 2.3179 - val_categorical_accuracy: 0.1219 - val_accuracy: 0.1219\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 84s 8s/step - loss: 2.2877 - categorical_accuracy: 0.1328 - accuracy: 0.1328 - val_loss: 2.2764 - val_categorical_accuracy: 0.1281 - val_accuracy: 0.1281\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 86s 9s/step - loss: 2.2860 - categorical_accuracy: 0.1063 - accuracy: 0.1063 - val_loss: 2.2812 - val_categorical_accuracy: 0.1156 - val_accuracy: 0.1156\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 80s 8s/step - loss: 2.2764 - categorical_accuracy: 0.1115 - accuracy: 0.1115 - val_loss: 2.3484 - val_categorical_accuracy: 0.1125 - val_accuracy: 0.1125\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 92s 9s/step - loss: 2.2882 - categorical_accuracy: 0.1125 - accuracy: 0.1125 - val_loss: 2.3036 - val_categorical_accuracy: 0.1125 - val_accuracy: 0.1125\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 82s 8s/step - loss: 2.2812 - categorical_accuracy: 0.1359 - accuracy: 0.1359 - val_loss: 2.2926 - val_categorical_accuracy: 0.1406 - val_accuracy: 0.1406\n",
      "Epoch 11/20\n",
      " 8/10 [=======================>......] - ETA: 11s - loss: 2.2797 - categorical_accuracy: 0.1152 - accuracy: 0.1152"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-47db9b837ae2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history2 = model2.fit(train_data,\n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     validation_steps=5)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(train_data,\n",
    "                    validation_data=test_data,\n",
    "                    epochs=20,\n",
    "                    steps_per_epoch=10,\n",
    "                    validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
